---
title: "Finding Closure: A Closer Look at the Gestalt Law of Closure in Convolutional Neural Networks"
collection: publications
permalink: /publication/2024-08-222_CNNClosure_Preprint
date: 2024-08-20
venue: 'arXiv preprint'
paperurl: 'https://arxiv.org/abs/2408.12460'
citation: 'Y. Zhang*, D. Soydaner*, L.  Ko√ümann, F. Behrad, J. Wagemans (2024). Finding Closure: A Closer Look at the Gestalt Law of Closure in Convolutional Neural Nerworks, arXiv preprint arXiv: 2408.12460.'
---
The human brain has an inherent ability to fill in gaps to perceive figures as complete wholes, even when parts are missing or fragmented. This phenomenon is known as Closure in
psychology, one of the Gestalt laws of perceptual organization, explaining how the human brain interprets visual stimuli. Given the importance of Closure for human object recog-
nition, we investigate whether neural networks rely on a similar mechanism. Exploring this crucial human visual skill in neural networks has the potential to highlight their comparability to humans. Recent studies have examined the Closure effect in neural networks. However, they typically focus on a limited selection of Convolutional Neural Networks (CNNs) and have not reached a consensus on their capability to perform Closure. To address these gaps, we present a systematic framework for investigating the Closure principle in neural networks. We introduce well-curated datasets designed to test for Closure effects, including both modal and amodal completion. We then conduct experiments on various CNNs employing different measurements. Our comprehensive analysis reveals that VGG16 and DenseNet-121 exhibit the Closure effect, while other CNNs show variable results. We interpret these findings by blending insights from psychology and neural network research, offering a unique perspective that enhances transparency in understanding neural networks. Our code and dataset will be made available on GitHub
[Download paper here](https://arxiv.org/pdf/2408.12460)